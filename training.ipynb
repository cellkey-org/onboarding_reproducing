{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "from train import train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# MPS 장치가 사용 가능한지 확인\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # BiLSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device) # 2 for bidirectional\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_deepmass_df = pd.read_csv(\"./data/renewal_deepmass.tsv\", sep=\"\\t\", low_memory=False)\n",
    "new_hela1_df = pd.read_csv(\"./data/renewal_hela1.tsv\", sep=\"\\t\", low_memory=False)\n",
    "new_hela2_df = pd.read_csv(\"./data/renewal_hela2.tsv\", sep=\"\\t\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = new_deepmass_df.sample(frac=0.4, random_state=44)\n",
    "train_df, val_df = train_test_split(sampled_df, test_size=0.3, random_state=44)\n",
    "\n",
    "max_seq_len = 35\n",
    "max_intens_len = 70\n",
    "\n",
    "train_dataset = preprocessing.retrieve_dataset(train_df, max_seq_len, max_intens_len)\n",
    "val_dataset = preprocessing.retrieve_dataset(val_df, max_seq_len, max_intens_len)\n",
    "hela1_dataset = preprocessing.retrieve_dataset(new_hela1_df, max_seq_len, max_intens_len)\n",
    "hela2_dataset = preprocessing.retrieve_dataset(new_hela2_df, max_seq_len, max_intens_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=258, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=258, shuffle=True)\n",
    "hela1_dataloader = DataLoader(hela1_dataset, batch_size=128, shuffle=True)\n",
    "hela2_dataloader = DataLoader(hela2_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1  # 입력 크기는 1 (각 시퀀스 값 하나씩 입력)\n",
    "hidden_size = 128  # 예시로 설정\n",
    "num_layers = 2  # 예시로 설정\n",
    "output_size = max_intens_len  # 출력 크기는 인텐시티 길이\n",
    "\n",
    "model = BiLSTM(input_size, hidden_size, num_layers, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return 1 - self.cosine_similarity(y_pred, y_true).mean()\n",
    "\n",
    "# 손실 함수 및 옵티마이저\n",
    "criterion = CosineSimilarityLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_res \u001b[38;5;241m=\u001b[39m train_model(\u001b[43mmodel\u001b[49m, criterion, optimizer, \u001b[38;5;241m50\u001b[39m, train_dataloader, val_dataloader, device)\n\u001b[1;32m      2\u001b[0m hela1_test_res \u001b[38;5;241m=\u001b[39m test_model(model, criterion, hela1_dataloader, device)\n\u001b[1;32m      3\u001b[0m hela2_test_res \u001b[38;5;241m=\u001b[39m test_model(model, criterion, hela2_dataloader, device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_res = train_model(model, criterion, optimizer, 50, train_dataloader, val_dataloader, device)\n",
    "hela1_test_res = test_model(model, criterion, hela1_dataloader, device)\n",
    "hela2_test_res = test_model(model, criterion, hela2_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_pearsonr(x, y):\n",
    "    \"\"\"\n",
    "    벡터화된 방식으로 배치의 피어슨 상관 계수를 계산합니다.\n",
    "    \"\"\"\n",
    "    mean_x = torch.mean(x, dim=1, keepdim=True)\n",
    "    mean_y = torch.mean(y, dim=1, keepdim=True)\n",
    "    xm = x - mean_x\n",
    "    ym = y - mean_y\n",
    "    r_num = torch.sum(xm * ym, dim=1)\n",
    "    r_den = torch.sqrt(torch.sum(xm ** 2, dim=1) * torch.sum(ym ** 2, dim=1))\n",
    "    r = r_num / r_den\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.0445, Validation Loss: 0.0443\n",
      "Train Cosine Similarity: 0.9556, Train PCC: 0.9447\n",
      "Validation Cosine Similarity: 0.9556, Validation PCC: 0.9448\n",
      "Epoch [2/30], Train Loss: 0.0425, Validation Loss: 0.0423\n",
      "Train Cosine Similarity: 0.9576, Train PCC: 0.9471\n",
      "Validation Cosine Similarity: 0.9576, Validation PCC: 0.9472\n",
      "Epoch [3/30], Train Loss: 0.0414, Validation Loss: 0.0423\n",
      "Train Cosine Similarity: 0.9586, Train PCC: 0.9484\n",
      "Validation Cosine Similarity: 0.9577, Validation PCC: 0.9474\n",
      "Epoch [4/30], Train Loss: 0.0403, Validation Loss: 0.0406\n",
      "Train Cosine Similarity: 0.9598, Train PCC: 0.9498\n",
      "Validation Cosine Similarity: 0.9593, Validation PCC: 0.9493\n",
      "Epoch [5/30], Train Loss: 0.0392, Validation Loss: 0.0408\n",
      "Train Cosine Similarity: 0.9609, Train PCC: 0.9512\n",
      "Validation Cosine Similarity: 0.9592, Validation PCC: 0.9492\n",
      "Epoch [6/30], Train Loss: 0.0384, Validation Loss: 0.0398\n",
      "Train Cosine Similarity: 0.9617, Train PCC: 0.9521\n",
      "Validation Cosine Similarity: 0.9601, Validation PCC: 0.9502\n",
      "Epoch [7/30], Train Loss: 0.0375, Validation Loss: 0.0379\n",
      "Train Cosine Similarity: 0.9625, Train PCC: 0.9532\n",
      "Validation Cosine Similarity: 0.9620, Validation PCC: 0.9525\n",
      "Epoch [8/30], Train Loss: 0.0364, Validation Loss: 0.0370\n",
      "Train Cosine Similarity: 0.9637, Train PCC: 0.9546\n",
      "Validation Cosine Similarity: 0.9631, Validation PCC: 0.9538\n",
      "Epoch [9/30], Train Loss: 0.0357, Validation Loss: 0.0365\n",
      "Train Cosine Similarity: 0.9643, Train PCC: 0.9554\n",
      "Validation Cosine Similarity: 0.9634, Validation PCC: 0.9543\n",
      "Epoch [10/30], Train Loss: 0.0350, Validation Loss: 0.0364\n",
      "Train Cosine Similarity: 0.9651, Train PCC: 0.9563\n",
      "Validation Cosine Similarity: 0.9634, Validation PCC: 0.9542\n",
      "Epoch [11/30], Train Loss: 0.0341, Validation Loss: 0.0366\n",
      "Train Cosine Similarity: 0.9660, Train PCC: 0.9574\n",
      "Validation Cosine Similarity: 0.9638, Validation PCC: 0.9548\n",
      "Epoch [12/30], Train Loss: 0.0332, Validation Loss: 0.0355\n",
      "Train Cosine Similarity: 0.9668, Train PCC: 0.9585\n",
      "Validation Cosine Similarity: 0.9644, Validation PCC: 0.9554\n",
      "Epoch [13/30], Train Loss: 0.0328, Validation Loss: 0.0339\n",
      "Train Cosine Similarity: 0.9673, Train PCC: 0.9591\n",
      "Validation Cosine Similarity: 0.9660, Validation PCC: 0.9575\n",
      "Epoch [14/30], Train Loss: 0.0321, Validation Loss: 0.0331\n",
      "Train Cosine Similarity: 0.9680, Train PCC: 0.9599\n",
      "Validation Cosine Similarity: 0.9674, Validation PCC: 0.9591\n",
      "Epoch [15/30], Train Loss: 0.0313, Validation Loss: 0.0339\n",
      "Train Cosine Similarity: 0.9688, Train PCC: 0.9608\n",
      "Validation Cosine Similarity: 0.9660, Validation PCC: 0.9575\n",
      "Epoch [16/30], Train Loss: 0.0308, Validation Loss: 0.0318\n",
      "Train Cosine Similarity: 0.9694, Train PCC: 0.9615\n",
      "Validation Cosine Similarity: 0.9682, Validation PCC: 0.9601\n",
      "Epoch [17/30], Train Loss: 0.0299, Validation Loss: 0.0318\n",
      "Train Cosine Similarity: 0.9702, Train PCC: 0.9626\n",
      "Validation Cosine Similarity: 0.9681, Validation PCC: 0.9601\n",
      "Epoch [18/30], Train Loss: 0.0295, Validation Loss: 0.0311\n",
      "Train Cosine Similarity: 0.9706, Train PCC: 0.9631\n",
      "Validation Cosine Similarity: 0.9688, Validation PCC: 0.9609\n",
      "Epoch [19/30], Train Loss: 0.0286, Validation Loss: 0.0303\n",
      "Train Cosine Similarity: 0.9715, Train PCC: 0.9642\n",
      "Validation Cosine Similarity: 0.9697, Validation PCC: 0.9621\n",
      "Epoch [20/30], Train Loss: 0.0282, Validation Loss: 0.0345\n",
      "Train Cosine Similarity: 0.9719, Train PCC: 0.9647\n",
      "Validation Cosine Similarity: 0.9656, Validation PCC: 0.9571\n",
      "Epoch [21/30], Train Loss: 0.0276, Validation Loss: 0.0291\n",
      "Train Cosine Similarity: 0.9725, Train PCC: 0.9655\n",
      "Validation Cosine Similarity: 0.9712, Validation PCC: 0.9638\n",
      "Epoch [22/30], Train Loss: 0.0270, Validation Loss: 0.0302\n",
      "Train Cosine Similarity: 0.9731, Train PCC: 0.9662\n",
      "Validation Cosine Similarity: 0.9697, Validation PCC: 0.9621\n",
      "Epoch [23/30], Train Loss: 0.0265, Validation Loss: 0.0284\n",
      "Train Cosine Similarity: 0.9736, Train PCC: 0.9668\n",
      "Validation Cosine Similarity: 0.9716, Validation PCC: 0.9643\n",
      "Epoch [24/30], Train Loss: 0.0261, Validation Loss: 0.0276\n",
      "Train Cosine Similarity: 0.9740, Train PCC: 0.9673\n",
      "Validation Cosine Similarity: 0.9723, Validation PCC: 0.9652\n",
      "Epoch [25/30], Train Loss: 0.0255, Validation Loss: 0.0272\n",
      "Train Cosine Similarity: 0.9747, Train PCC: 0.9681\n",
      "Validation Cosine Similarity: 0.9727, Validation PCC: 0.9657\n",
      "Epoch [26/30], Train Loss: 0.0251, Validation Loss: 0.0268\n",
      "Train Cosine Similarity: 0.9751, Train PCC: 0.9686\n",
      "Validation Cosine Similarity: 0.9732, Validation PCC: 0.9663\n",
      "Epoch [27/30], Train Loss: 0.0245, Validation Loss: 0.0261\n",
      "Train Cosine Similarity: 0.9756, Train PCC: 0.9693\n",
      "Validation Cosine Similarity: 0.9740, Validation PCC: 0.9673\n",
      "Epoch [28/30], Train Loss: 0.0241, Validation Loss: 0.0263\n",
      "Train Cosine Similarity: 0.9761, Train PCC: 0.9698\n",
      "Validation Cosine Similarity: 0.9736, Validation PCC: 0.9669\n",
      "Epoch [29/30], Train Loss: 0.0236, Validation Loss: 0.0255\n",
      "Train Cosine Similarity: 0.9766, Train PCC: 0.9705\n",
      "Validation Cosine Similarity: 0.9745, Validation PCC: 0.9679\n",
      "Epoch [30/30], Train Loss: 0.0232, Validation Loss: 0.0257\n",
      "Train Cosine Similarity: 0.9770, Train PCC: 0.9710\n",
      "Validation Cosine Similarity: 0.9743, Validation PCC: 0.9677\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    cosine_similarities = []\n",
    "    pearson_coefficients = []\n",
    "\n",
    "    for sequences, intensities in train_dataloader:\n",
    "        sequences = sequences.float().unsqueeze(2).to(device)  # (batch_size, sequence_length, input_size)\n",
    "        intensities = intensities.float().to(device)\n",
    "\n",
    "        # 순전파\n",
    "        outputs = model(sequences)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, intensities)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 역전파 및 옵티마이저 스텝\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 코사인 유사도 계산\n",
    "        cosine_similarity = F.cosine_similarity(outputs, intensities, dim=1)\n",
    "        cosine_similarities.extend(cosine_similarity.cpu().detach().numpy())\n",
    "\n",
    "        # 벡터화된 피어슨 상관 계수 계산\n",
    "        pearson_coefficient = batch_pearsonr(outputs, intensities)\n",
    "        pearson_coefficients.extend(pearson_coefficient.cpu().detach().numpy())\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    mean_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities)\n",
    "    mean_pearson_coefficient = sum(pearson_coefficients) / len(pearson_coefficients)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    cosine_similarities_val = []\n",
    "    pearson_coefficients_val = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, intensities in val_dataloader:\n",
    "            sequences = sequences.float().unsqueeze(2).to(device)\n",
    "            intensities = intensities.float().to(device)\n",
    "\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, intensities)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # 코사인 유사도 계산 (Validation)\n",
    "            cosine_similarity_val = F.cosine_similarity(outputs, intensities, dim=1)\n",
    "            cosine_similarities_val.extend(cosine_similarity_val.cpu().detach().numpy())\n",
    "\n",
    "            # 벡터화된 피어슨 상관 계수 계산 (Validation)\n",
    "            pearson_coefficient_val = batch_pearsonr(outputs, intensities)\n",
    "            pearson_coefficients_val.extend(pearson_coefficient_val.cpu().detach().numpy())\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    mean_cosine_similarity_val = sum(cosine_similarities_val) / len(cosine_similarities_val)\n",
    "    mean_pearson_coefficient_val = sum(pearson_coefficients_val) / len(pearson_coefficients_val)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    print(f'Train Cosine Similarity: {mean_cosine_similarity:.4f}, Train PCC: {mean_pearson_coefficient:.4f}')\n",
    "    print(f'Validation Cosine Similarity: {mean_cosine_similarity_val:.4f}, Validation PCC: {mean_pearson_coefficient_val:.4f}')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.6926\n",
      "Mean Pearson Correlation Coefficient: 0.6615\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cosine_similarities = []\n",
    "pearson_coefficients = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, intensities in hela1_dataloader:\n",
    "        sequences = sequences.float().unsqueeze(2).to(device)\n",
    "        intensities = intensities.float().to(device)\n",
    "\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, intensities)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        # 코사인 유사도 계산 (Validation)\n",
    "        cosine_similarity = F.cosine_similarity(outputs, intensities, dim=1)\n",
    "        cosine_similarities.extend(cosine_similarity.cpu().detach().numpy())\n",
    "\n",
    "        # 벡터화된 피어슨 상관 계수 계산 (Validation)\n",
    "        pearson_coefficient = batch_pearsonr(outputs, intensities)\n",
    "        pearson_coefficients.extend(pearson_coefficient.cpu().detach().numpy())\n",
    "\n",
    "# 평균 코사인 유사도 및 피어슨 상관 계수 계산\n",
    "mean_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities)\n",
    "mean_pearson_coefficient = sum(pearson_coefficients) / len(pearson_coefficients)\n",
    "\n",
    "print(f'Mean Cosine Similarity: {mean_cosine_similarity:.4f}')\n",
    "print(f'Mean Pearson Correlation Coefficient: {mean_pearson_coefficient:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.6781\n",
      "Mean Pearson Correlation Coefficient: 0.6445\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "cosine_similarities = []\n",
    "pearson_coefficients = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, intensities in hela2_dataloader:\n",
    "        sequences = sequences.float().unsqueeze(2).to(device)\n",
    "        intensities = intensities.float().to(device)\n",
    "\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, intensities)\n",
    "        val_loss += loss.item()\n",
    "        \n",
    "        # 코사인 유사도 계산 (Validation)\n",
    "        cosine_similarity = F.cosine_similarity(outputs, intensities, dim=1)\n",
    "        cosine_similarities.extend(cosine_similarity.cpu().detach().numpy())\n",
    "\n",
    "        # 벡터화된 피어슨 상관 계수 계산 (Validation)\n",
    "        pearson_coefficient = batch_pearsonr(outputs, intensities)\n",
    "        pearson_coefficients.extend(pearson_coefficient.cpu().detach().numpy())\n",
    "\n",
    "# 평균 코사인 유사도 및 피어슨 상관 계수 계산\n",
    "mean_cosine_similarity = sum(cosine_similarities) / len(cosine_similarities)\n",
    "mean_pearson_coefficient = sum(pearson_coefficients) / len(pearson_coefficients)\n",
    "\n",
    "print(f'Mean Cosine Similarity: {mean_cosine_similarity:.4f}')\n",
    "print(f'Mean Pearson Correlation Coefficient: {mean_pearson_coefficient:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgz_reproduce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
